{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20441923-9b4c-4c6c-87b2-24e3f93e638b",
   "metadata": {},
   "source": [
    "# Variable dependiente: Corrupción Intensa (dicotómica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83588d-21c5-482b-9a30-93fb486073ae",
   "metadata": {},
   "source": [
    "## 1. Load data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b347cf-1513-4fc9-880c-a0bef2a8a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7f2b1f-13c4-44b1-ae99-21e610fbf6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d031ebd0-f647-4e9f-be1d-5ee2284b029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "path = r'..\\..\\output\\data_preprocess\\dfs_0_i_base3_a.csv'\n",
    "data = pd.read_csv( path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7cd645-9230-4a95-8507-84207f7b06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar columnas con missing values\n",
    "data = data.dropna( axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2343315f-7352-4d46-a0aa-7207c86053ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1969, 4697)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d51e4d-52e9-4d0e-90da-2fdc93f105fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.576943\n",
       "0.0    0.423057\n",
       "Name: corrup_intensa, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[ 'corrup_intensa' ].value_counts( normalize = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863270e-519f-4def-9a3e-000d9ed4cc31",
   "metadata": {},
   "source": [
    "## 2. Split variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbc5c9a-e77a-4cc4-8d98-39f363556638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6187f08-6f18-4b10-bf07-46285888b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = [ 'corrup_intensa' ]\n",
    "other_vars = [ 'monto_examinado', 'monto_auditado', 'monto_objeto_servicio', \n",
    "               'monto_corrup1', 'monto_corrup2', 'tipo_control', 'corrup_amplia',\n",
    "               'per_corrup1', 'per_corrup2', '_monto', 'monto_' ]\n",
    "pred_vars = [ col for col in data.columns if col not in dep_var and col not in other_vars ]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( data[ pred_vars ], data[ 'corrup_intensa' ], test_size = 0.25 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119dc4d-eb22-4211-a9f3-2db9e439b153",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb21e21-716a-405c-bc9e-4f82a8f9f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss, roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11d31af-c0fe-47d4-b586-a7d701a83c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Implementing the model\n",
    "lg_model = LogisticRegression().fit( x_train, y_train )\n",
    "\n",
    "# Predict over test set\n",
    "y_lg_pred_class = lg_model.predict( x_test )\n",
    "y_lg_pred_prob = lg_model.predict_proba( x_test )[ :, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a9e318-0744-40f7-9f85-2f3c7b9ebd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics\n",
    "columns = [ 'no', 'si' ]\n",
    "lg_report = classification_report(y_test, y_lg_pred_class, target_names = columns, output_dict = True )\n",
    "\n",
    "lg_no_precision = lg_report[ 'no' ][ 'precision' ]\n",
    "lg_no_recall = lg_report[ 'no' ][ 'recall' ]\n",
    "lg_no_f1_score = lg_report[ 'no' ][ 'f1-score' ]\n",
    "\n",
    "lg_si_precision = lg_report[ 'si' ][ 'precision' ]\n",
    "lg_si_recall = lg_report[ 'si' ][ 'recall' ]\n",
    "lg_si_f1_score = lg_report[ 'si' ][ 'f1-score' ]\n",
    "\n",
    "accuracy_lg = accuracy_score( y_test, y_lg_pred_class )\n",
    "log_loss_lg = log_loss( y_test, y_lg_pred_class )\n",
    "roc_auc_lg = roc_auc_score( y_test, y_lg_pred_prob )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b317da1-201e-4c72-b144-4fd59a7493d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6531440162271805"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75946b-4aa1-46f9-b7ae-12764e6aabfd",
   "metadata": {},
   "source": [
    "## 4. Regularization Methods (Lasso, Ridge and Elastic Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e1962f4-dd16-4777-a590-d89cea9d0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31b8ce-4aee-48b8-bdce-dd858441f8b6",
   "metadata": {},
   "source": [
    "## 4.1. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c71c8f6-79a9-4242-9932-5514c2a74488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Implementing the model\n",
    "lasso_model = LogisticRegressionCV( penalty = 'l1', solver = 'saga', cv = 10, random_state = 0 ).fit( x_train, y_train )\n",
    "\n",
    "# Predict over test set\n",
    "y_lasso_pred_class = lasso_model.predict( x_test )\n",
    "y_lasso_pred_prob = lasso_model.predict_proba( x_test )[ :, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a07d1fb4-57c2-4acb-97da-0331b5ef4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics\n",
    "columns = [ 'no', 'si' ]\n",
    "lasso_report = classification_report(y_test, y_lasso_pred_class, target_names = columns, output_dict = True )\n",
    "\n",
    "lasso_no_precision = lasso_report[ 'no' ][ 'precision' ]\n",
    "lasso_no_recall = lasso_report[ 'no' ][ 'recall' ]\n",
    "lasso_no_f1_score = lasso_report[ 'no' ][ 'f1-score' ]\n",
    "\n",
    "lasso_si_precision = lasso_report[ 'si' ][ 'precision' ]\n",
    "lasso_si_recall = lasso_report[ 'si' ][ 'recall' ]\n",
    "lasso_si_f1_score = lasso_report[ 'si' ][ 'f1-score' ]\n",
    "\n",
    "accuracy_lasso = accuracy_score( y_test, y_lasso_pred_class )\n",
    "log_loss_lasso = log_loss( y_test, y_lasso_pred_class )\n",
    "roc_auc_lasso = roc_auc_score( y_test, y_lasso_pred_prob )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb248f-7bdf-4759-8fb2-cea5b6caac44",
   "metadata": {},
   "source": [
    "## 4.2. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa5f976-95a6-4d89-b3ce-b1696e1ea7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Implementing the model\n",
    "ridge_model = LogisticRegressionCV( penalty = 'l2', solver = 'saga', cv = 10, random_state = 0 ).fit( x_train, y_train )\n",
    "\n",
    "# Predict over test set\n",
    "y_ridge_pred_class = ridge_model.predict( x_test )\n",
    "y_ridge_pred_prob = ridge_model.predict_proba( x_test )[ :, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f3c13c2-63d4-4dd0-bf8e-0e2ca4aaf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics\n",
    "columns = [ 'no', 'si' ]\n",
    "ridge_report = classification_report( y_test, y_ridge_pred_class, target_names = columns, output_dict = True )\n",
    "\n",
    "ridge_no_precision = ridge_report[ 'no' ][ 'precision' ]\n",
    "ridge_no_recall = ridge_report[ 'no' ][ 'recall' ]\n",
    "ridge_no_f1_score = ridge_report[ 'no' ][ 'f1-score' ]\n",
    "\n",
    "ridge_si_precision = ridge_report[ 'si' ][ 'precision' ]\n",
    "ridge_si_recall = ridge_report[ 'si' ][ 'recall' ]\n",
    "ridge_si_f1_score = ridge_report[ 'si' ][ 'f1-score' ]\n",
    "\n",
    "accuracy_ridge = accuracy_score( y_test, y_ridge_pred_class )\n",
    "log_loss_ridge = log_loss( y_test, y_ridge_pred_class )\n",
    "roc_auc_ridge = roc_auc_score( y_test, y_ridge_pred_prob )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc9cf1-c42c-402e-b703-74549afd90b0",
   "metadata": {},
   "source": [
    "### 4.3. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd032ec1-7426-4e5f-a95a-03ba52f460c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Implementing the model\n",
    "elasticnet_model = LogisticRegressionCV( penalty = 'elasticnet', solver = 'saga', cv = 10, random_state = 0, l1_ratios = [ 0.5 ] ).\\\n",
    "                                  fit( x_train, y_train )\n",
    "\n",
    "# Predict over test set\n",
    "y_elasticnet_pred_class = elasticnet_model.predict( x_test )\n",
    "y_elasticnet_pred_prob = elasticnet_model.predict_proba( x_test )[ :, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b0421e2-baa0-4aab-8ca0-5ff218eba627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics\n",
    "columns = [ 'no', 'si' ]\n",
    "elasticnet_report = classification_report( y_test, y_elasticnet_pred_class, target_names = columns, output_dict = True )\n",
    "\n",
    "elasticnet_no_precision = elasticnet_report[ 'no' ][ 'precision' ]\n",
    "elasticnet_no_recall = elasticnet_report[ 'no' ][ 'recall' ]\n",
    "elasticnet_no_f1_score = elasticnet_report[ 'no' ][ 'f1-score' ]\n",
    "\n",
    "elasticnet_si_precision = elasticnet_report[ 'si' ][ 'precision' ]\n",
    "elasticnet_si_recall = elasticnet_report[ 'si' ][ 'recall' ]\n",
    "elasticnet_si_f1_score = elasticnet_report[ 'si' ][ 'f1-score' ]\n",
    "\n",
    "accuracy_elasticnet = accuracy_score( y_test, y_elasticnet_pred_class )\n",
    "log_loss_elasticnet = log_loss( y_test, y_elasticnet_pred_class )\n",
    "roc_auc_elasticnet = roc_auc_score( y_test, y_elasticnet_pred_prob )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df796fff-eadc-4c69-b7fa-6853601b39d6",
   "metadata": {},
   "source": [
    "## 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "339e91e6-3c2d-4e4a-b5bf-890898dc71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d961295d-aed9-445d-af93-727c53241b10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 2000}\n",
      "Wall time: 45min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set the model\n",
    "rf_model = RandomForestClassifier( random_state = 0 )\n",
    "\n",
    "# Define param grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [ 500, 1000, 2000 ],\n",
    "    'max_features': [ 'auto', 'sqrt', 'log2' ]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "rf_search = GridSearchCV( estimator = rf_model,\n",
    "                          param_grid = rf_param_grid )\n",
    "\n",
    "# Fit to data\n",
    "rf_search.fit( x_train, y_train )\n",
    "\n",
    "# Print best params and best score\n",
    "print( rf_search.best_params_ )\n",
    "\n",
    "# Select best params\n",
    "rf_max_features = rf_search.best_params_[ 'max_features' ] \n",
    "rf_n_estimators = rf_search.best_params_[ 'n_estimators' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36d7ba1d-fdc4-4014-b735-5975e89d75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the optimal model\n",
    "rf_optimal_model = RandomForestClassifier( max_features = rf_max_features, \n",
    "                                           n_estimators = rf_n_estimators )\n",
    "rf_optimal_model.fit( x_train, y_train )\n",
    "\n",
    "# Apply over test set\n",
    "y_rf_pred_class = rf_optimal_model.predict( x_test )\n",
    "y_rf_pred_prob = rf_optimal_model.predict_proba( x_test )[ :, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "300ba667-9eeb-4bb0-9600-8395d256b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics\n",
    "columns = [ 'no', 'si' ]\n",
    "rf_report = classification_report(y_test, y_rf_pred_class, target_names = columns, output_dict = True )\n",
    "\n",
    "rf_no_precision = rf_report[ 'no' ][ 'precision' ]\n",
    "rf_no_recall = rf_report[ 'no' ][ 'recall' ]\n",
    "rf_no_f1_score = rf_report[ 'no' ][ 'f1-score' ]\n",
    "\n",
    "rf_si_precision = rf_report[ 'si' ][ 'precision' ]\n",
    "rf_si_recall = rf_report[ 'si' ][ 'recall' ]\n",
    "rf_si_f1_score = rf_report[ 'si' ][ 'f1-score' ]\n",
    "\n",
    "accuracy_rf = accuracy_score( y_test, y_rf_pred_class )\n",
    "log_loss_rf = log_loss( y_test, y_rf_pred_class )\n",
    "roc_auc_rf = roc_auc_score( y_test, y_rf_pred_prob )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ad86c-eb38-43e4-b5c3-0f78da50766e",
   "metadata": {},
   "source": [
    "## 6. Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38aa3a9a-9f56-4f2d-bd12-ff8982dadd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0d6a434-90b4-48ab-a8e2-b7123c52bedb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         )\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set the model\n",
    "xgb_model = XGBClassifier( use_label_encoder = False, objective = 'binary:logistic', verbosity = 0 )\n",
    "\n",
    "# Define param grid\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [ 500, 1000, 2000 ],\n",
    "    'learning_rate': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "xgb_search = GridSearchCV( estimator = xgb_model,\n",
    "                           param_grid = xgb_param_grid )\n",
    "\n",
    "# Fit to data\n",
    "xgb_search.fit( x_train, y_train )\n",
    "\n",
    "# Print best params and best score\n",
    "print( xgb_search.best_params_ )\n",
    "\n",
    "# Select best params\n",
    "xgb_learning_rate = xgb_search.best_params_[ 'learning_rate' ] \n",
    "xgb_n_estimators = xgb_search.best_params_[ 'n_estimators' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2c4d214-9058-4f95-968b-78391b96df1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2396\\4147139103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m xgb_optimal_model = XGBClassifier( objective = 'binary:logistic', \n\u001b[0;32m      3\u001b[0m                                    \u001b[0mverbosity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                    \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                                    n_estimators = xgb_n_estimators )\n\u001b[0;32m      6\u001b[0m \u001b[0mxgb_optimal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the optimal model\n",
    "xgb_optimal_model = XGBClassifier( objective = 'binary:logistic', \n",
    "                                   verbosity = 0,\n",
    "                                   learning_rate = xgb_learning_rate, \n",
    "                                   n_estimators = xgb_n_estimators )\n",
    "xgb_optimal_model.fit( x_train, y_train )\n",
    "\n",
    "# Apply over test set\n",
    "y_xgb_pred_class = xgb_optimal_model.predict( x_test )\n",
    "y_xgb_pred_prob = xgb_optimal_model.predict_proba( x_test )[ :, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c177d8d-c95a-4c23-9f9a-d07f31976670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics\n",
    "columns = [ 'no', 'si' ]\n",
    "xgb_report = classification_report(y_test, y_xgb_pred_class, target_names = columns, output_dict = True )\n",
    "\n",
    "xgb_no_precision = xgb_report[ 'no' ][ 'precision' ]\n",
    "xgb_no_recall = xgb_report[ 'no' ][ 'recall' ]\n",
    "xgb_no_f1_score = xgb_report[ 'no' ][ 'f1-score' ]\n",
    "\n",
    "xgb_si_precision = xgb_report[ 'si' ][ 'precision' ]\n",
    "xgb_si_recall = xgb_report[ 'si' ][ 'recall' ]\n",
    "xgb_si_f1_score = xgb_report[ 'si' ][ 'f1-score' ]\n",
    "\n",
    "accuracy_xgb = accuracy_score( y_test, y_xgb_pred_class )\n",
    "log_loss_xgb = log_loss( y_test, y_xgb_pred_class )\n",
    "roc_auc_xgb = roc_auc_score( y_test, y_xgb_pred_prob )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54dd529-7134-4afa-a985-b91234ec63d4",
   "metadata": {},
   "source": [
    "## 4. Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "781ee6a5-178f-4f35-802d-6d17fbdd6bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Accuracy</th>\n",
       "      <th>Roc_Auc</th>\n",
       "      <th>No_Precision</th>\n",
       "      <th>No_Recall</th>\n",
       "      <th>No_F1_Score</th>\n",
       "      <th>Si_Precision</th>\n",
       "      <th>Si_Recall</th>\n",
       "      <th>Si_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.688</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.696</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic Net</th>\n",
       "      <td>0.688</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.712</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Overall_Accuracy  Roc_Auc  No_Precision  No_Recall  \\\n",
       "Logistic Regression             0.653    0.719         0.606      0.575   \n",
       "Lasso                           0.688    0.751         0.660      0.579   \n",
       "Ridge                           0.696    0.758         0.695      0.533   \n",
       "Elastic Net                     0.688    0.740         0.688      0.514   \n",
       "Random Forest                   0.712    0.726         0.714      0.561   \n",
       "\n",
       "                     No_F1_Score  Si_Precision  Si_Recall  Si_F1_Score  \n",
       "Logistic Regression        0.590         0.686      0.713        0.699  \n",
       "Lasso                      0.617         0.705      0.771        0.736  \n",
       "Ridge                      0.603         0.696      0.821        0.753  \n",
       "Elastic Net                0.588         0.688      0.821        0.748  \n",
       "Random Forest              0.628         0.711      0.828        0.765  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = np.zeros( ( 5, 8 ) )\n",
    "# table = np.zeros( ( 6, 8 ) )\n",
    "\n",
    "table[ 0 ] = [ accuracy_lg, roc_auc_lg, lg_no_precision, lg_no_recall, \n",
    "               lg_no_f1_score, lg_si_precision, lg_si_recall, lg_si_f1_score ]\n",
    "\n",
    "table[ 1 ] = [ accuracy_lasso, roc_auc_lasso, lasso_no_precision, lasso_no_recall, \n",
    "               lasso_no_f1_score, lasso_si_precision, lasso_si_recall, lasso_si_f1_score ]\n",
    "\n",
    "table[ 2 ] = [ accuracy_ridge, roc_auc_ridge, ridge_no_precision, ridge_no_recall, \n",
    "               ridge_no_f1_score, ridge_si_precision, ridge_si_recall, ridge_si_f1_score ]\n",
    "\n",
    "table[ 3 ] = [ accuracy_elasticnet, roc_auc_elasticnet, elasticnet_no_precision, elasticnet_no_recall, \n",
    "               elasticnet_no_f1_score, elasticnet_si_precision, elasticnet_si_recall, elasticnet_si_f1_score ]\n",
    "\n",
    "table[ 4 ] = [ accuracy_rf, roc_auc_rf, rf_no_precision, rf_no_recall, \n",
    "               rf_no_f1_score, rf_si_precision, rf_si_recall, rf_si_f1_score ]\n",
    "\n",
    "# table[ 5 ] = [ accuracy_xgb, roc_auc_xgb, xgb_no_precision, xgb_no_recall, \n",
    "               # xgb_no_f1_score, xgb_si_precision, xgb_si_recall, xgb_si_f1_score ]\n",
    "\n",
    "colnames_table = [ \"Overall_Accuracy\", \"Roc_Auc\", \"No_Precision\", \"No_Recall\",\n",
    "                   \"No_F1_Score\", \"Si_Precision\", \"Si_Recall\", \"Si_F1_Score\" ]\n",
    "                  \n",
    "rownames_table = [ \"Logistic Regression\", \"Lasso\",\n",
    "                   \"Ridge\", \"Elastic Net\",\n",
    "                   \"Random Forest\" ]\n",
    "\n",
    "# rownames_table = [ \"Logistic Regression\", \"Lasso\",\n",
    "                   # \"Ridge\", \"Elastic Net\",\n",
    "                   # \"Random Forest\", \"Boosted Trees\" ]\n",
    "\n",
    "table_pandas = pd.DataFrame( table, columns = colnames_table )\n",
    "table_pandas.index = rownames_table\n",
    "\n",
    "table_pandas = table_pandas.round(3)\n",
    "table_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e99aa0-bb34-4a90-a984-18ab3702cdb0",
   "metadata": {},
   "source": [
    "## 8. Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a355cf35-4c5a-4974-99d9-f8f7a169f01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pimgge_r18ct05pobso    0.002336\n",
       "piagge_r18ct05pobso    0.001908\n",
       "pimgct_r09gstcr        0.001823\n",
       "pimgge_r09ct05biser    0.001816\n",
       "tdvgge_r18ct05pobso    0.001773\n",
       "piagge_r09ct05biser    0.001758\n",
       "tdvgfun_ct05opseg      0.001750\n",
       "pimgft_redr            0.001742\n",
       "pimgrb_redr            0.001739\n",
       "piagft_redr            0.001657\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "fp_randomforest = pd.Series( rf_optimal_model.feature_importances_, index = pred_vars).\\\n",
    "                  sort_values( ascending = False )\n",
    "fp_randomforest.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a9325-7092-4e73-9be8-28c5c518a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted Trees\n",
    "fp_xgboost = pd.Series( xgb_optimal_model.feature_importances_, index = pred_vars).\\\n",
    "           sort_values( ascending = False )\n",
    "fp_xgboost.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
